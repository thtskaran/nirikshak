# Nirikshak: LLM Safety Monitoring & Red Teaming System

# Overview

Nirikshak is designed to monitor and ensure the safety of Large Language Model (LLM) deployments. It focuses on analyzing interactions with these models to detect and mitigate unsafe outputs, leveraging a combination of logging, real-time monitoring, and red teaming techniques.

1. **Log Source:**

   - Logs to be analyzed and monitored are **Ollama logs** (from model deployments and interactions) — **not** system-wide logs, not from Kafka/Elastic/Filebeat, etc.
   - The focus is on **monitoring LLM usage/activity**, not generic server/application logs.

2. **Red Teaming Agent:**

   - The adversarial agent used for red teaming is **Dolphin-3** (the unfiltered LLM, e.g., Dolphin 3 by FreedomGPT or similar).
   - **No need to create a special red teaming module** — simply spin up Dolphin-3, instruct it as a red teamer (with a crafted system prompt), and have it converse with the deployed model to probe for unsafe outputs.
   - All prompts and interactions for red teaming are generated by **Dolphin-3**, acting as the adversarial user.

---

# Updated Technical Architecture: Nirikshak

## 1. Component Breakdown

### A. **Model Deployment & Management**

- **User Panel (Web/UI):**

  - Deploy a model: Input name, description, select model type (Ollama or Hugging Face), set parameters (system prompt, temperature, etc.).
  - On deploy, a container is started with the model (via Ollama API for Ollama models, or direct Hugging Face loading).
  - Each model gets a proxied endpoint for all usage.

### B. **Proxy Endpoint & Safety Pipeline**

- Every incoming query to the deployed model is routed through a **proxy endpoint**:

  - **Request** is logged (with identifiers, timestamps, etc.).
  - **Model’s response** is passed to **LlamaGuard** (running in a separate container via Ollama or as a lightweight service).
  - If **safe**, forward output to user and log as SAFE.
  - If **unsafe**, **block** output, return “unsafe response” warning (with mapped safety code S1-S14), log as UNSAFE.

### C. **Red Teaming with Dolphin-3**

- On new deployment:

  - **Dolphin-3** is spun up (as a containerized Ollama model).
  - **System prompt for Dolphin-3:** instruct it to “behave as a red team adversary; attempt to provoke the deployed model into unsafe/harmful responses by any means possible.”
  - For a fixed duration (e.g., 10 mins):

    - **Dolphin-3 auto-generates prompts** targeting all S1–S14 categories.
    - Prompts sent to the new deployed model via proxy; **responses are checked by LlamaGuard**.
    - All interactions and outcomes logged.

  - **At end:** Generate PDF report listing:

    - Prompts tried.
    - Responses & LlamaGuard safety verdicts.
    - Recommendation: safe/unsafe, suggested system prompt if unsafe, and model auto-stopped if severe.

- **No separate logic for adversarial prompt generation**; **Dolphin-3** does this via its own LLM capabilities (with appropriate priming).

### D. **Log Storage & Audit**

- **All logs** = Ollama logs (model usage, request/response, safe/unsafe verdict).
- **Minimal logging**: request id, model, timestamp, truncated input/output, LlamaGuard status, and if unsafe, the S-code.
- Logs are **encrypted** and stored in an S3-compatible bucket.
- Log metadata and S3 links are stored in MongoDB.
- Only the log owner or admin can decrypt/retrieve full logs for audits.

### E. **Database**

- MongoDB for:

  - Model deployments, settings.
  - Proxy endpoint metadata.
  - Red teaming report references.
  - Log indexes (pointing to S3 locations).
  - User/session/auth records.

### F. **Dashboard**

- Web-based, shows:

  - Model deployment status.
  - Current model endpoints.
  - Red teaming report PDFs (download).
  - Search/filter logs by model, status, S-code.
  - Audit actions (who did what/when).

---

## 2. **Tech Stack & Implementation Suggestions**

### **Languages & Frameworks**

- **Python (FastAPI or Flask)**: backend orchestration, API, proxy endpoints.
- **React/Next.js**: web dashboard.
- **Docker**: containerization for models, LlamaGuard, Dolphin-3 agent.
- **Ollama API**: run/manage models locally, including LlamaGuard and Dolphin-3.
- **MongoDB**: metadata DB.
- **S3/MinIO**: log/report storage.

### **Key Libraries**

- **PyPDF2/ReportLab**: generate PDF reports.
- **Cryptography**: for encrypting logs.
- **Pydantic**: data validation in backend.
- **Boto3/Minio-py**: for S3 storage integration.

### **How Components Communicate**

- **Model endpoints** exposed internally (localhost/network namespace, not public).
- **Proxy** communicates with model containers via HTTP API (secured, only inside trusted network).
- **LlamaGuard** exposed as an internal REST service (container).
- **Dolphin-3** agent communicates via API with the deployed model’s endpoint, as any other client would, for red teaming.
- All services talk to MongoDB and S3 via secure local network endpoints.

### **Container Orchestration**

- Use **Docker Compose** for simple setups, or **Kubernetes** for larger scale (if multiple concurrent deployments).

### **Offline Operation**

- All images/models/downloads are kept local; Hugging Face integration can use offline mirror.
- All logs and data processing happen strictly inside the air-gapped/offline network.

---

## 3. **Security & Data Privacy**

- **Logs** are encrypted before being sent to S3.
- **API/Panel** is secured with auth (JWT/OAuth2).
- No data leaves the closed network.
- **All model endpoints** are accessible only via the internal proxy (no direct access).
- All red teaming and LlamaGuard evaluation happens on local infrastructure.

---

## 4. **Summary Architecture Diagram**

```mermaid
graph TD
    UserPanel(Web UI) --> BackendAPI
    BackendAPI --> MongoDB
    BackendAPI --> S3
    BackendAPI --> ProxyEndpoint
    ProxyEndpoint --> DeployedModel
    ProxyEndpoint --> LlamaGuard
    ProxyEndpoint --> S3
    BackendAPI --> RedTeamRunner
    RedTeamRunner --> Dolphin3
    Dolphin3 --> ProxyEndpoint
    RedTeamRunner --> PDFReport
    PDFReport --> S3
    UserPanel(Web UI) --> PDFReport
```

---

## 5. **Implementation How-to (High-Level Flow)**

1. **User deploys model** via panel.
2. **Backend pulls** model via Ollama or Hugging Face, sets system prompt & params.
3. **Container with model** started; proxy endpoint created.
4. **Red teaming** starts: Dolphin-3 (with “adversary” prompt) is spun up, sends probes, responses filtered by LlamaGuard.
5. **After red teaming**:

   - PDF report generated, stored in S3, referenced in MongoDB.
   - If unsafe, model is stopped/quarantined; otherwise, exposed to user/API.

6. **During usage**:

   - All API traffic to model is proxied, logged, filtered by LlamaGuard.
   - All logs are minimal, encrypted, and S3-stored, with indexes in MongoDB.
   - Admins can view/download logs and reports via the dashboard.
